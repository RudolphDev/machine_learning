{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python386jvsc74a57bd0916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1",
   "display_name": "Python 3.8.6 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_data_tp1_app = open_file('../data/data_tp1_app.txt')\n",
    "split_data_tp1_dec = open_file('../data/data_tp1_dec.txt')\n",
    "\n",
    "split_data_tp2_app = open_file('../data/data_tp2_app.txt')\n",
    "split_data_tp2_dec = open_file('../data/data_tp2_dec.txt')\n",
    "\n",
    "split_data_tp3_app = open_file('../data/data_tp3_app.txt')\n",
    "split_data_tp3_dec = open_file('../data/data_tp3_dec.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-39-2bfd281b1e30>:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hyperplan_data.iloc[(hyperplan_data[0] == hyper_plan[0]), 0] = 0\n",
      "<ipython-input-39-2bfd281b1e30>:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hyperplan_data.iloc[(hyperplan_data[0] == hyper_plan[1]), 0] = 1\n",
      "[-91.  29.  29.]\n",
      "[1.296000e+02 2.196114e+05 2.196114e+05]\n",
      "[  1069.4        654311.39999999 654311.39999999]\n",
      "[4.940000e+01 3.944914e+05 3.944914e+05]\n",
      "[-760.2 3614.4 3614.4]\n",
      "[2.0000e+01 4.0299e+05 4.0299e+05]\n",
      "[ -1000. 143170. 143170.]\n",
      "[  1069.4        466607.40000001 466607.40000001]\n",
      "[4.940000e+01 2.067874e+05 2.067874e+05]\n",
      "[   980. 439180. 439180.]\n"
     ]
    }
   ],
   "source": [
    "def create_hyperplans_classes(train_data):\n",
    "    hyper_plans_classes = []\n",
    "    classes = get_unique_class_num(train_data)\n",
    "    for i in range(len(classes)):\n",
    "        for j in range(i+1, len(classes)):\n",
    "            hyper_plans_classes.append((classes[i], classes[j]))\n",
    "    return hyper_plans_classes\n",
    "\n",
    "def predict(weights, inputs):\n",
    "    weight_sum = np.dot(inputs, weights[1:]) + weights[0]\n",
    "    if weight_sum > 0:\n",
    "        prediction = 1\n",
    "    else:\n",
    "        prediction = 0            \n",
    "    return prediction\n",
    "\n",
    "def linear_perceptron_two_classes(train_data, learning_rate = 0.2, n = 100):\n",
    "    weights = np.zeros(len(train_data.columns))\n",
    "    for _ in range(n):\n",
    "        for index, row in train_data.iterrows():\n",
    "            temp_line = row.tolist()\n",
    "            line = list(map(float, temp_line))\n",
    "            prediction = predict(weights, line[1:])\n",
    "\n",
    "            weights[1:] += learning_rate * (line[0] - prediction) * index\n",
    "            weights[0] += learning_rate * (line[0] - prediction)\n",
    "    return weights\n",
    "\n",
    "def linear_train(train_data, learning_rate = 0.2, n = 100):\n",
    "    hyper_plan_list = create_hyperplans_classes(train_data)\n",
    "    data_pd = pd.DataFrame(train_data)\n",
    "    for hyper_plan in hyper_plan_list:\n",
    "\n",
    "        hyperplan_data = data_pd[(data_pd[0] == hyper_plan[0]) | (data_pd[0] == hyper_plan[1])]\n",
    "        hyperplan_data.iloc[(hyperplan_data[0] == hyper_plan[0]), 0] = 0\n",
    "        hyperplan_data.iloc[(hyperplan_data[0] == hyper_plan[1]), 0] = 1\n",
    "        weights = linear_perceptron_two_classes(hyperplan_data, learning_rate, n)\n",
    "        print(weights)\n",
    "\n",
    "linear_train(split_data_tp1_app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}