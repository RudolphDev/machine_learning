{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python386jvsc74a57bd0916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1",
   "display_name": "Python 3.8.6 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_data_tp1_app = open_file('../data/data_tp1_app.txt')\n",
    "split_data_tp1_dec = open_file('../data/data_tp1_dec.txt')\n",
    "\n",
    "split_data_tp2_app = open_file('../data/data_tp2_app.txt')\n",
    "split_data_tp2_dec = open_file('../data/data_tp2_dec.txt')\n",
    "\n",
    "split_data_tp3_app = open_file('../data/data_tp3_app.txt')\n",
    "split_data_tp3_dec = open_file('../data/data_tp3_dec.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-42-5bcd1520d62f>:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hyperplan_data.iloc[(hyperplan_data[0] == hyper_plan[0]), 0] = 0\n",
      "<ipython-input-42-5bcd1520d62f>:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hyperplan_data.iloc[(hyperplan_data[0] == hyper_plan[1]), 0] = 1\n",
      "Epoch : 1, error = 1.0\n",
      "Epoch : 2, error = 3.0\n",
      "Epoch : 3, error = 0.0\n",
      "Epoch : 4, error = 0.0\n",
      "Epoch : 5, error = 0.0\n",
      "For the hyperplan : ('1', '2'), the weights are : [ 0.          0.25055288 -0.02368656]\n",
      "Epoch : 1, error = 1.0\n",
      "Epoch : 2, error = 0.0\n",
      "Epoch : 3, error = 0.0\n",
      "Epoch : 4, error = 0.0\n",
      "Epoch : 5, error = 0.0\n",
      "For the hyperplan : ('1', '3'), the weights are : [ 0.02        0.18270684 -0.11640598]\n",
      "Epoch : 1, error = 1.0\n",
      "Epoch : 2, error = 2.0\n",
      "Epoch : 3, error = 2.0\n",
      "Epoch : 4, error = 0.0\n",
      "Epoch : 5, error = 0.0\n",
      "For the hyperplan : ('1', '4'), the weights are : [ 0.02        0.03953294 -0.31198724]\n",
      "Epoch : 1, error = 4.0\n",
      "Epoch : 2, error = 5.0\n",
      "Epoch : 3, error = 5.0\n",
      "Epoch : 4, error = 4.0\n",
      "Epoch : 5, error = 0.0\n",
      "For the hyperplan : ('1', '5'), the weights are : [ 0.24        0.01383514 -0.06429706]\n",
      "Epoch : 1, error = 1.0\n",
      "Epoch : 2, error = 1.0\n",
      "Epoch : 3, error = 0.0\n",
      "Epoch : 4, error = 0.0\n",
      "Epoch : 5, error = 0.0\n",
      "For the hyperplan : ('2', '3'), the weights are : [ 0.          0.03702108 -0.26363304]\n",
      "Epoch : 1, error = 1.0\n",
      "Epoch : 2, error = 0.0\n",
      "Epoch : 3, error = 0.0\n",
      "Epoch : 4, error = 0.0\n",
      "Epoch : 5, error = 0.0\n",
      "For the hyperplan : ('2', '4'), the weights are : [ 0.02       -0.11648652 -0.16051786]\n",
      "Epoch : 1, error = 4.0\n",
      "Epoch : 2, error = 5.0\n",
      "Epoch : 3, error = 4.0\n",
      "Epoch : 4, error = 5.0\n",
      "Epoch : 5, error = 4.0\n",
      "For the hyperplan : ('2', '5'), the weights are : [0.28       0.04910562 0.0022594 ]\n",
      "Epoch : 1, error = 1.0\n",
      "Epoch : 2, error = 1.0\n",
      "Epoch : 3, error = 0.0\n",
      "Epoch : 4, error = 0.0\n",
      "Epoch : 5, error = 0.0\n",
      "For the hyperplan : ('3', '4'), the weights are : [ 0.         -0.26809622 -0.01667228]\n",
      "Epoch : 1, error = 4.0\n",
      "Epoch : 2, error = 9.0\n",
      "Epoch : 3, error = 6.0\n",
      "Epoch : 4, error = 2.0\n",
      "Epoch : 5, error = 0.0\n",
      "For the hyperplan : ('3', '5'), the weights are : [ 0.3        -0.05553956  0.08111266]\n",
      "Epoch : 1, error = 4.0\n",
      "Epoch : 2, error = 4.0\n",
      "Epoch : 3, error = 6.0\n",
      "Epoch : 4, error = 5.0\n",
      "Epoch : 5, error = 2.0\n",
      "For the hyperplan : ('4', '5'), the weights are : [0.26       0.07148616 0.0515456 ]\n"
     ]
    }
   ],
   "source": [
    "def create_hyperplans_classes(train_data):\n",
    "    hyper_plans_classes = []\n",
    "    classes = get_unique_class_num(train_data)\n",
    "    for i in range(len(classes)):\n",
    "        for j in range(i+1, len(classes)):\n",
    "            hyper_plans_classes.append((classes[i], classes[j]))\n",
    "    return hyper_plans_classes\n",
    "\n",
    "def predict(weights, inputs):\n",
    "    weight_sum = np.dot(inputs, weights[1:]) + weights[0]\n",
    "    if weight_sum > 0:\n",
    "        prediction = 1\n",
    "    else:\n",
    "        prediction = 0            \n",
    "    return prediction\n",
    "\n",
    "def linear_perceptron_two_classes(train_data, learning_rate = 0.2, n = 100):\n",
    "    weights = np.zeros(len(train_data.columns))\n",
    "    for epoch in range(n):\n",
    "        sum_error = 0.0\n",
    "        for index, row in train_data.iterrows():\n",
    "            temp_line = row.tolist()\n",
    "            line = list(map(float, temp_line))\n",
    "            prediction = predict(weights, line[1:])\n",
    "            error = line[0] - prediction\n",
    "            sum_error += error**2\n",
    "            for i in range(len(line[1:])):\n",
    "                weights[i+1] += learning_rate * error * line[i+1]\n",
    "            weights[0] += learning_rate * error\n",
    "        print(\"Epoch : {}, error = {}\".format(epoch+1, sum_error))\n",
    "    return weights\n",
    "\n",
    "def linear_train(train_data, learning_rate = 0.2, n = 100):\n",
    "    hyper_plan_list = create_hyperplans_classes(train_data)\n",
    "    data_pd = pd.DataFrame(train_data)\n",
    "    for hyper_plan in hyper_plan_list:\n",
    "\n",
    "        hyperplan_data = data_pd[(data_pd[0] == hyper_plan[0]) | (data_pd[0] == hyper_plan[1])]\n",
    "        hyperplan_data.iloc[(hyperplan_data[0] == hyper_plan[0]), 0] = 0\n",
    "        hyperplan_data.iloc[(hyperplan_data[0] == hyper_plan[1]), 0] = 1\n",
    "        weights = linear_perceptron_two_classes(hyperplan_data, learning_rate, n)\n",
    "        print(\"For the hyperplan : {}, the weights are : {}\".format(hyper_plan, weights))\n",
    "\n",
    "\n",
    "linear_train(split_data_tp1_app, 0.02, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[2.7810836, 2.550537003, 0]\n2.7810836\n2.550537003\n>epoch=0, lrate=0.100, error=1.000\n[1.465489372, 2.362125076, 0]\n1.465489372\n2.362125076\n>epoch=0, lrate=0.100, error=1.000\n[3.396561688, 4.400293529, 0]\n3.396561688\n4.400293529\n>epoch=0, lrate=0.100, error=1.000\n[1.38807019, 1.850220317, 0]\n1.38807019\n1.850220317\n>epoch=0, lrate=0.100, error=1.000\n[3.06407232, 3.005305973, 0]\n3.06407232\n3.005305973\n>epoch=0, lrate=0.100, error=1.000\n[7.627531214, 2.759262235, 1]\n7.627531214\n2.759262235\n>epoch=0, lrate=0.100, error=2.000\n[5.332441248, 2.088626775, 1]\n5.332441248\n2.088626775\n>epoch=0, lrate=0.100, error=2.000\n[6.922596716, 1.77106367, 1]\n6.922596716\n1.77106367\n>epoch=0, lrate=0.100, error=2.000\n[8.675418651, -0.242068655, 1]\n8.675418651\n-0.242068655\n>epoch=0, lrate=0.100, error=3.000\n[7.673756466, 3.508563011, 1]\n7.673756466\n3.508563011\n>epoch=0, lrate=0.100, error=3.000\n[2.7810836, 2.550537003, 0]\n2.7810836\n2.550537003\n>epoch=1, lrate=0.100, error=1.000\n[1.465489372, 2.362125076, 0]\n1.465489372\n2.362125076\n>epoch=1, lrate=0.100, error=1.000\n[3.396561688, 4.400293529, 0]\n3.396561688\n4.400293529\n>epoch=1, lrate=0.100, error=1.000\n[1.38807019, 1.850220317, 0]\n1.38807019\n1.850220317\n>epoch=1, lrate=0.100, error=1.000\n[3.06407232, 3.005305973, 0]\n3.06407232\n3.005305973\n>epoch=1, lrate=0.100, error=1.000\n[7.627531214, 2.759262235, 1]\n7.627531214\n2.759262235\n>epoch=1, lrate=0.100, error=2.000\n[5.332441248, 2.088626775, 1]\n5.332441248\n2.088626775\n>epoch=1, lrate=0.100, error=2.000\n[6.922596716, 1.77106367, 1]\n6.922596716\n1.77106367\n>epoch=1, lrate=0.100, error=2.000\n[8.675418651, -0.242068655, 1]\n8.675418651\n-0.242068655\n>epoch=1, lrate=0.100, error=2.000\n[7.673756466, 3.508563011, 1]\n7.673756466\n3.508563011\n>epoch=1, lrate=0.100, error=2.000\n[2.7810836, 2.550537003, 0]\n2.7810836\n2.550537003\n>epoch=2, lrate=0.100, error=1.000\n[1.465489372, 2.362125076, 0]\n1.465489372\n2.362125076\n>epoch=2, lrate=0.100, error=1.000\n[3.396561688, 4.400293529, 0]\n3.396561688\n4.400293529\n>epoch=2, lrate=0.100, error=1.000\n[1.38807019, 1.850220317, 0]\n1.38807019\n1.850220317\n>epoch=2, lrate=0.100, error=1.000\n[3.06407232, 3.005305973, 0]\n3.06407232\n3.005305973\n>epoch=2, lrate=0.100, error=1.000\n[7.627531214, 2.759262235, 1]\n7.627531214\n2.759262235\n>epoch=2, lrate=0.100, error=2.000\n[5.332441248, 2.088626775, 1]\n5.332441248\n2.088626775\n>epoch=2, lrate=0.100, error=2.000\n[6.922596716, 1.77106367, 1]\n6.922596716\n1.77106367\n>epoch=2, lrate=0.100, error=2.000\n[8.675418651, -0.242068655, 1]\n8.675418651\n-0.242068655\n>epoch=2, lrate=0.100, error=2.000\n[7.673756466, 3.508563011, 1]\n7.673756466\n3.508563011\n>epoch=2, lrate=0.100, error=2.000\n[2.7810836, 2.550537003, 0]\n2.7810836\n2.550537003\n>epoch=3, lrate=0.100, error=1.000\n[1.465489372, 2.362125076, 0]\n1.465489372\n2.362125076\n>epoch=3, lrate=0.100, error=1.000\n[3.396561688, 4.400293529, 0]\n3.396561688\n4.400293529\n>epoch=3, lrate=0.100, error=1.000\n[1.38807019, 1.850220317, 0]\n1.38807019\n1.850220317\n>epoch=3, lrate=0.100, error=1.000\n[3.06407232, 3.005305973, 0]\n3.06407232\n3.005305973\n>epoch=3, lrate=0.100, error=1.000\n[7.627531214, 2.759262235, 1]\n7.627531214\n2.759262235\n>epoch=3, lrate=0.100, error=2.000\n[5.332441248, 2.088626775, 1]\n5.332441248\n2.088626775\n>epoch=3, lrate=0.100, error=2.000\n[6.922596716, 1.77106367, 1]\n6.922596716\n1.77106367\n>epoch=3, lrate=0.100, error=2.000\n[8.675418651, -0.242068655, 1]\n8.675418651\n-0.242068655\n>epoch=3, lrate=0.100, error=2.000\n[7.673756466, 3.508563011, 1]\n7.673756466\n3.508563011\n>epoch=3, lrate=0.100, error=2.000\n[2.7810836, 2.550537003, 0]\n2.7810836\n2.550537003\n>epoch=4, lrate=0.100, error=1.000\n[1.465489372, 2.362125076, 0]\n1.465489372\n2.362125076\n>epoch=4, lrate=0.100, error=1.000\n[3.396561688, 4.400293529, 0]\n3.396561688\n4.400293529\n>epoch=4, lrate=0.100, error=1.000\n[1.38807019, 1.850220317, 0]\n1.38807019\n1.850220317\n>epoch=4, lrate=0.100, error=1.000\n[3.06407232, 3.005305973, 0]\n3.06407232\n3.005305973\n>epoch=4, lrate=0.100, error=1.000\n[7.627531214, 2.759262235, 1]\n7.627531214\n2.759262235\n>epoch=4, lrate=0.100, error=2.000\n[5.332441248, 2.088626775, 1]\n5.332441248\n2.088626775\n>epoch=4, lrate=0.100, error=2.000\n[6.922596716, 1.77106367, 1]\n6.922596716\n1.77106367\n>epoch=4, lrate=0.100, error=2.000\n[8.675418651, -0.242068655, 1]\n8.675418651\n-0.242068655\n>epoch=4, lrate=0.100, error=2.000\n[7.673756466, 3.508563011, 1]\n7.673756466\n3.508563011\n>epoch=4, lrate=0.100, error=2.000\n[0.1, 0.0, 0.08015575049999996]\n"
     ]
    }
   ],
   "source": [
    "# Make a prediction with weights\n",
    "def predict(row, weights):\n",
    "    activation = weights[0]\n",
    "    for i in range(len(row)-1):\n",
    "        activation += weights[i + 1] * row[i]\n",
    "    return 1.0 if activation >= 0.0 else 0.0\n",
    "\n",
    "# Estimate Perceptron weights using stochastic gradient descent\n",
    "def train_weights(train, l_rate, n_epoch):\n",
    "    weights = [0.0 for i in range(len(train[0]))]\n",
    "    for epoch in range(n_epoch):\n",
    "        sum_error = 0.0\n",
    "        for row in train:\n",
    "            prediction = predict(row, weights)\n",
    "            error = row[-1] - prediction\n",
    "            sum_error += error**2\n",
    "            weights[0] = weights[0] + l_rate * error\n",
    "            print(row)\n",
    "            for i in range(len(row)-1):\n",
    "                print(row[i])\n",
    "            weights[i + 1] = weights[i + 1] + l_rate * error * row[i]\n",
    "            print('>epoch=%d, lrate=%.3f, error=%.3f' % (epoch, l_rate, sum_error))\n",
    "    return weights\n",
    "\n",
    "# Calculate weights\n",
    "dataset = [[2.7810836,2.550537003,0],\n",
    "\t[1.465489372,2.362125076,0],\n",
    "\t[3.396561688,4.400293529,0],\n",
    "\t[1.38807019,1.850220317,0],\n",
    "\t[3.06407232,3.005305973,0],\n",
    "\t[7.627531214,2.759262235,1],\n",
    "\t[5.332441248,2.088626775,1],\n",
    "\t[6.922596716,1.77106367,1],\n",
    "\t[8.675418651,-0.242068655,1],\n",
    "\t[7.673756466,3.508563011,1]]\n",
    "l_rate = 0.1\n",
    "n_epoch = 5\n",
    "weights = train_weights(dataset, l_rate, n_epoch)\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}