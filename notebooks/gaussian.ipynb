{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ImportError",
     "evalue": "attempted relative import with no known parent package",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-d50c01f52106>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# local functions import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmachine_learning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctions\u001b[0m \u001b[0;32mimport\u001b[0m  \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: attempted relative import with no known parent package"
     ]
    }
   ],
   "source": [
    "# General import\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import linalg\n",
    "\n",
    "# local functions import\n",
    "from functions import  *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'open_file' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e1644c424524>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msplit_data_tp1_app\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/data_tp1_app.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msplit_data_tp1_dec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/data_tp1_dec.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msplit_data_tp2_app\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/data_tp2_app.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msplit_data_tp2_dec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/data_tp2_dec.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'open_file' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "split_data_tp1_app = open_file('../data/data_tp1_app.txt')\n",
    "split_data_tp1_dec = open_file('../data/data_tp1_dec.txt')\n",
    "\n",
    "split_data_tp2_app = open_file('../data/data_tp2_app.txt')\n",
    "split_data_tp2_dec = open_file('../data/data_tp2_dec.txt')\n",
    "\n",
    "split_data_tp3_app = open_file('../data/data_tp3_app.txt')\n",
    "split_data_tp3_dec = open_file('../data/data_tp3_dec.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_fit_model(data):\n",
    "    class_centers = {}\n",
    "    classes = get_unique_class_num(data)\n",
    "    for class_num in classes:\n",
    "        data_class = get_splited_class(data, int(class_num))\n",
    "        sum_x = 0\n",
    "        sum_y = 0\n",
    "        for line in data_class:\n",
    "            sum_x += float(line[1])\n",
    "            sum_y += float(line[2])\n",
    "        x_center = 1/len(data_class) * sum_x\n",
    "        y_center = 1/len(data_class) * sum_y\n",
    "        class_centers[class_num] = [x_center, y_center]\n",
    "    return class_centers\n",
    "\n",
    "def compute_one_euclidian_dist(first_point, second_point):\n",
    "    sum_square = 0\n",
    "    for i in range(0, len(first_point)):\n",
    "        sum_square = (float(first_point[i]) - float(second_point[i]))**2      \n",
    "    return math.sqrt(sum_square)\n",
    "\n",
    "def compute_euclidian_dists(class_centers, line):\n",
    "    dists_dict = {}\n",
    "    for class_center in class_centers:\n",
    "        dist = compute_one_euclidian_dist(class_centers[class_center], line[1:3])\n",
    "        dists_dict[class_center] = dist   \n",
    "    return dists_dict\n",
    "\n",
    "def euclidian_test_model(class_centers, app_data, dec_data):\n",
    "    classes_num =get_unique_class_num(app_data)\n",
    "    conf_matrix = np.zeros((len(classes_num), len(classes_num)))\n",
    "    count_top1 = 0\n",
    "    count_top2 = 0\n",
    "    for line in dec_data:\n",
    "        dists = compute_euclidian_dists(class_centers, line)\n",
    "        if get_top_n_decision(1, line[0], dists):\n",
    "            count_top1 = count_top1 + 1\n",
    "        if get_top_n_decision(2, line[0], dists):\n",
    "            count_top2 = count_top2 + 1\n",
    "        update_confusion_matrix(conf_matrix, line[0], dists)\n",
    "    df = transform_matrix_to_df(conf_matrix, classes_num)\n",
    "    print_decision_model_result(len(app_data), len(dec_data), count_top1/len(dec_data), count_top2/len(dec_data), df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mahalanobis_dists(class_centers, line, inv_covmat):\n",
    "    dists_dict = {}\n",
    "    for class_center in class_centers:\n",
    "        dist = compute_one_mahalanobis_dist(line[1:3], class_centers[class_center], inv_covmat)\n",
    "        dists_dict[class_center] = dist   \n",
    "    return dists_dict\n",
    "\n",
    "def compute_inv_covmat(dec_data):\n",
    "    data  = pd.DataFrame(dec_data, dtype=float)[[1,2]]\n",
    "    cov = np.cov(data.values.T)\n",
    "    inv_covmat = linalg.inv(cov)\n",
    "    return inv_covmat\n",
    "\n",
    "def compute_one_mahalanobis_dist(first_point, second_point, inv_covmat):\n",
    "    x_minus_mu = []\n",
    "    for i in range(0, len(first_point)):\n",
    "        x_minus_mu.append(float(first_point[i]) - second_point[i])\n",
    "    x_minus_mu = np.array(x_minus_mu)\n",
    "    left_term = np.dot(x_minus_mu, inv_covmat)\n",
    "    mahal = np.dot(left_term, x_minus_mu.T)\n",
    "    return math.sqrt(mahal)\n",
    "\n",
    "def mahalanobis_test_model(class_centers, app_data, dec_data):\n",
    "    classes_num =get_unique_class_num(app_data)\n",
    "    conf_matrix = np.zeros((len(classes_num), len(classes_num)))\n",
    "    count_top1 = 0\n",
    "    count_top2 = 0\n",
    "    inv_covmat = compute_inv_covmat(dec_data)\n",
    "    for line in dec_data:\n",
    "        dists = compute_mahalanobis_dists(class_centers, line, inv_covmat)\n",
    "        if get_top_n_decision(1, line[0], dists):\n",
    "            count_top1 = count_top1 + 1\n",
    "        if get_top_n_decision(2, line[0], dists):\n",
    "            count_top2 = count_top2 + 1\n",
    "        update_confusion_matrix(conf_matrix, line[0], dists)\n",
    "    df = transform_matrix_to_df(conf_matrix, classes_num)\n",
    "    print_decision_model_result(len(app_data), len(dec_data), count_top1/len(dec_data), count_top2/len(dec_data), df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "First Data TP1\n\tResults :\n\t----------------\n\tNumber of elements for the learning step :  500\n\tNumber of elements for the decision step :  500\n\t----------------\n\n\tTop results :\n\t----------------\n\tTop 1 rate :  0.576\n\tTop 2 rate :  0.962\n\t----------------\n\n\tConfusion matrix :\n\t----------------\n╒════╤═════╤═════╤═════╤═════╤═════╕\n│    │   1 │   2 │   3 │   4 │   5 │\n╞════╪═════╪═════╪═════╪═════╪═════╡\n│  1 │  40 │  56 │   0 │   0 │   4 │\n├────┼─────┼─────┼─────┼─────┼─────┤\n│  2 │  41 │  51 │   0 │   0 │   8 │\n├────┼─────┼─────┼─────┼─────┼─────┤\n│  3 │   0 │   0 │  42 │  58 │   0 │\n├────┼─────┼─────┼─────┼─────┼─────┤\n│  4 │   0 │   0 │  34 │  60 │   6 │\n├────┼─────┼─────┼─────┼─────┼─────┤\n│  5 │   1 │   0 │   4 │   0 │  95 │\n╘════╧═════╧═════╧═════╧═════╧═════╛\n\t----------------\n\tExecution time : 0.012201547622680664 seconds\n\n==========================\n\nFirst Data TP2\n\tResults :\n\t----------------\n\tNumber of elements for the learning step :  500\n\tNumber of elements for the decision step :  500\n\t----------------\n\n\tTop results :\n\t----------------\n\tTop 1 rate :  0.522\n\tTop 2 rate :  0.926\n\t----------------\n\n\tConfusion matrix :\n\t----------------\n╒════╤═════╤═════╤═════╤═════╤═════╕\n│    │   1 │   2 │   3 │   4 │   5 │\n╞════╪═════╪═════╪═════╪═════╪═════╡\n│  1 │  48 │   0 │   2 │   0 │  50 │\n├────┼─────┼─────┼─────┼─────┼─────┤\n│  2 │   0 │  47 │  10 │  43 │   0 │\n├────┼─────┼─────┼─────┼─────┼─────┤\n│  3 │   9 │   0 │  82 │   8 │   1 │\n├────┼─────┼─────┼─────┼─────┼─────┤\n│  4 │   0 │  46 │  18 │  36 │   0 │\n├────┼─────┼─────┼─────┼─────┼─────┤\n│  5 │  42 │   0 │  10 │   0 │  48 │\n╘════╧═════╧═════╧═════╧═════╧═════╛\n\t----------------\n\tExecution time : 0.00954127311706543 seconds\n\n==========================\n\nFirst Data TP3\n\tResults :\n\t----------------\n\tNumber of elements for the learning step :  500\n\tNumber of elements for the decision step :  500\n\t----------------\n\n\tTop results :\n\t----------------\n\tTop 1 rate :  0.398\n\tTop 2 rate :  0.762\n\t----------------\n\n\tConfusion matrix :\n\t----------------\n╒════╤═════╤═════╤═════╤═════╤═════╕\n│    │   1 │   2 │   3 │   4 │   5 │\n╞════╪═════╪═════╪═════╪═════╪═════╡\n│  1 │  44 │  12 │  19 │   8 │  17 │\n├────┼─────┼─────┼─────┼─────┼─────┤\n│  2 │  17 │  56 │  27 │   0 │   0 │\n├────┼─────┼─────┼─────┼─────┼─────┤\n│  3 │  26 │  46 │  27 │   0 │   1 │\n├────┼─────┼─────┼─────┼─────┼─────┤\n│  4 │  27 │   1 │   3 │  47 │  22 │\n├────┼─────┼─────┼─────┼─────┼─────┤\n│  5 │  14 │   0 │   5 │  56 │  25 │\n╘════╧═════╧═════╧═════╧═════╧═════╛\n\t----------------\n\tExecution time : 0.007804393768310547 seconds\n\n==========================\n\n"
     ]
    }
   ],
   "source": [
    "print(\"First Data TP1\")\n",
    "start_time = time.time()\n",
    "model = gaussian_fit_model(split_data_tp1_app)\n",
    "euclidian_test_model(model, split_data_tp1_app, split_data_tp1_dec)\n",
    "print(\"\\tExecution time : %s seconds\\n\" % (time.time() - start_time))\n",
    "print(\"==========================\\n\")\n",
    "\n",
    "print(\"First Data TP2\")\n",
    "start_time = time.time()\n",
    "model = gaussian_fit_model(split_data_tp2_app)\n",
    "euclidian_test_model(model, split_data_tp2_app, split_data_tp2_dec)\n",
    "print(\"\\tExecution time : %s seconds\\n\" % (time.time() - start_time))\n",
    "print(\"==========================\\n\")\n",
    "\n",
    "print(\"First Data TP3\")\n",
    "start_time = time.time()\n",
    "model = gaussian_fit_model(split_data_tp3_app)\n",
    "euclidian_test_model(model, split_data_tp3_app, split_data_tp3_dec)\n",
    "print(\"\\tExecution time : %s seconds\\n\" % (time.time() - start_time))\n",
    "print(\"==========================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "First Data TP1\n\tResults :\n\t----------------\n\tNumber of elements for the learning step :  500\n\tNumber of elements for the decision step :  500\n\t----------------\n\n\tTop results :\n\t----------------\n\tTop 1 rate :  0.992\n\tTop 2 rate :  1.0\n\t----------------\n\n\tConfusion matrix :\n\t----------------\n╒════╤═════╤═════╤═════╤═════╤═════╕\n│    │   1 │   2 │   3 │   4 │   5 │\n╞════╪═════╪═════╪═════╪═════╪═════╡\n│  1 │  98 │   0 │   0 │   0 │   2 │\n├────┼─────┼─────┼─────┼─────┼─────┤\n│  2 │   0 │ 100 │   0 │   0 │   0 │\n├────┼─────┼─────┼─────┼─────┼─────┤\n│  3 │   0 │   0 │  99 │   1 │   0 │\n├────┼─────┼─────┼─────┼─────┼─────┤\n│  4 │   0 │   0 │   0 │ 100 │   0 │\n├────┼─────┼─────┼─────┼─────┼─────┤\n│  5 │   1 │   0 │   0 │   0 │  99 │\n╘════╧═════╧═════╧═════╧═════╧═════╛\n\t----------------\n\tExecution time : 0.05135011672973633 seconds\n\n==========================\n\nFirst Data TP2\n\tResults :\n\t----------------\n\tNumber of elements for the learning step :  500\n\tNumber of elements for the decision step :  500\n\t----------------\n\n\tTop results :\n\t----------------\n\tTop 1 rate :  0.946\n\tTop 2 rate :  0.996\n\t----------------\n\n\tConfusion matrix :\n\t----------------\n╒════╤═════╤═════╤═════╤═════╤═════╕\n│    │   1 │   2 │   3 │   4 │   5 │\n╞════╪═════╪═════╪═════╪═════╪═════╡\n│  1 │ 100 │   0 │   0 │   0 │   0 │\n├────┼─────┼─────┼─────┼─────┼─────┤\n│  2 │   2 │  97 │   1 │   0 │   0 │\n├────┼─────┼─────┼─────┼─────┼─────┤\n│  3 │   0 │   5 │  84 │   1 │  10 │\n├────┼─────┼─────┼─────┼─────┼─────┤\n│  4 │   0 │   0 │   6 │  94 │   0 │\n├────┼─────┼─────┼─────┼─────┼─────┤\n│  5 │   0 │   0 │   2 │   0 │  98 │\n╘════╧═════╧═════╧═════╧═════╧═════╛\n\t----------------\n\tExecution time : 0.01671314239501953 seconds\n\n==========================\n\nFirst Data TP3\n\tResults :\n\t----------------\n\tNumber of elements for the learning step :  500\n\tNumber of elements for the decision step :  500\n\t----------------\n\n\tTop results :\n\t----------------\n\tTop 1 rate :  0.728\n\tTop 2 rate :  0.894\n\t----------------\n\n\tConfusion matrix :\n\t----------------\n╒════╤═════╤═════╤═════╤═════╤═════╕\n│    │   1 │   2 │   3 │   4 │   5 │\n╞════╪═════╪═════╪═════╪═════╪═════╡\n│  1 │  43 │  17 │  16 │  12 │  12 │\n├────┼─────┼─────┼─────┼─────┼─────┤\n│  2 │  12 │  83 │   3 │   0 │   2 │\n├────┼─────┼─────┼─────┼─────┼─────┤\n│  3 │  16 │   4 │  78 │   2 │   0 │\n├────┼─────┼─────┼─────┼─────┼─────┤\n│  4 │  16 │   0 │   7 │  74 │   3 │\n├────┼─────┼─────┼─────┼─────┼─────┤\n│  5 │   5 │   9 │   0 │   0 │  86 │\n╘════╧═════╧═════╧═════╧═════╧═════╛\n\t----------------\n\tExecution time : 0.016837596893310547 seconds\n\n==========================\n\n"
     ]
    }
   ],
   "source": [
    "print(\"First Data TP1\")\n",
    "start_time = time.time()\n",
    "model = gaussian_fit_model(split_data_tp1_app)\n",
    "mahalanobis_test_model(model, split_data_tp1_app, split_data_tp1_dec)\n",
    "print(\"\\tExecution time : %s seconds\\n\" % (time.time() - start_time))\n",
    "print(\"==========================\\n\")\n",
    "\n",
    "print(\"First Data TP2\")\n",
    "start_time = time.time()\n",
    "model = gaussian_fit_model(split_data_tp2_app)\n",
    "mahalanobis_test_model(model, split_data_tp2_app, split_data_tp2_dec)\n",
    "print(\"\\tExecution time : %s seconds\\n\" % (time.time() - start_time))\n",
    "print(\"==========================\\n\")\n",
    "\n",
    "print(\"First Data TP3\")\n",
    "start_time = time.time()\n",
    "model = gaussian_fit_model(split_data_tp3_app)\n",
    "mahalanobis_test_model(model, split_data_tp3_app, split_data_tp3_dec)\n",
    "print(\"\\tExecution time : %s seconds\\n\" % (time.time() - start_time))\n",
    "print(\"==========================\\n\")"
   ]
  }
 ]
}